datahub-gms:
  enabled: true
  image:
    repository: acryldata/datahub-gms
    tag: head
  env:
    DATAHUB_SERVER_TYPE: quickstart
  resources:
    limits:
      memory: 1Gi
    requests:
      cpu: 100m
      memory: 1Gi
  livenessProbe:
    initialDelaySeconds: 60
    periodSeconds: 30
    failureThreshold: 8
  readinessProbe:
    initialDelaySeconds: 120
    periodSeconds: 30
    failureThreshold: 8

datahub-frontend:
  enabled: true
  image:
    repository: acryldata/datahub-frontend-react
    tag: head
  env:
    DATAHUB_SECRET: YouKnowNothing
  resources:
    limits:
      memory: 1400Mi
    requests:
      cpu: 100m
      memory: 512Mi
  ingress:
    enabled: false
  defaultUserCredentials: {}
  
acryl-datahub-actions:
  enabled: true
  image:
    repository: acryldata/datahub-actions
    tag: "head"
  env:
    DATAHUB_SYSTEM_CLIENT_SECRET: JohnSnowKnowsNothing
  resources:
    limits:
      memory: 512Mi
    requests:
      cpu: 300m
      memory: 256Mi

datahub-mae-consumer:
  image:
    repository: acryldata/datahub-mae-consumer
    tag: "head"
  resources:
    limits:
      memory: 1536Mi
    requests:
      cpu: 100m
      memory: 256Mi

datahub-mce-consumer:
  image:
    repository: acryldata/datahub-mce-consumer
    tag: "head"
  resources:
    limits:
      memory: 1536Mi
    requests:
      cpu: 100m
      memory: 256Mi

datahub-ingestion-cron:
  enabled: false

elasticsearchSetupJob:
  enabled: true
  image:
    repository: acryldata/datahub-elasticsearch-setup
    tag: "head"
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 300m
      memory: 256Mi
  extraInitContainers: []
  podSecurityContext:
    fsGroup: 1000
  securityContext:
    runAsUser: 1000
  annotations:
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-weight: "-5"
    helm.sh/hook-delete-policy: before-hook-creation
  podAnnotations: {}
  extraSidecars: []

kafkaSetupJob:
  enabled: true
  image:
    repository: acryldata/datahub-kafka-setup
    tag: "head"
  resources:
    limits:
      cpu: 500m
      memory: 1024Mi
    requests:
      cpu: 300m
      memory: 768Mi
  extraInitContainers: []
  podSecurityContext:
    fsGroup: 1000
  securityContext:
    runAsUser: 1000
  annotations:
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-weight: "-5"
    helm.sh/hook-delete-policy: before-hook-creation
  podAnnotations: {}
  extraSidecars: []

mysqlSetupJob:
  enabled: false
  image:
    repository: acryldata/datahub-mysql-setup
    tag: "head"
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 300m
      memory: 256Mi
  extraInitContainers: []
  podSecurityContext:
    fsGroup: 1000
  securityContext:
    runAsUser: 1000
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-weight: "-5"
    helm.sh/hook-delete-policy: before-hook-creation
  podAnnotations: {}
  extraSidecars: []

## No code data migration
datahubUpgrade:
  enabled: false
  image:
    repository: acryldata/datahub-upgrade
    # tag: "v0.11.0"  # defaults to .global.datahub.version
  batchSize: 1000
  batchDelayMs: 100
  noCodeDataMigration:
    image:
      # Add custom command / arguments to this job.  Useful if you need a custom startup or shutdown script
      # to run
      command:
      args: []
    sqlDbType: "MYSQL"
  podSecurityContext: {} # fsGroup: 1000
  securityContext: {} # runAsUser: 1000
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "-2"
    helm.sh/hook-delete-policy: before-hook-creation
  podAnnotations: {}
  extraSidecars: []
  cleanupJob:
    image:
      command:
      args: []
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 300m
        memory: 256Mi
    concurrencyPolicy: Allow
    extraSidecars: []
  restoreIndices:
    image:
      # Add custom command / arguments to this job.  Useful if you need a custom startup or shutdown script
      # to run
      command:
      args: []
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 300m
        memory: 256Mi
    schedule: "0 0 * * 0"
    concurrencyPolicy: Allow
    extraSidecars: []
  extraInitContainers: []

datahubSystemUpdate:
  enabled: false
  image:
    repository: acryldata/datahub-upgrade
  podSecurityContext: {}
  securityContext: {}
  annotations:
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-weight: "-4"
    helm.sh/hook-delete-policy: before-hook-creation
  nonblocking:
    enabled: false
    annotations:
      helm.sh/hook: post-install,post-upgrade
      helm.sh/hook-delete-policy: before-hook-creation
    image:
      args:
  podAnnotations: {}
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 300m
      memory: 256Mi
  extraSidecars: []
  extraInitContainers: []

global:
  strict_mode: true
  graph_service_impl: elasticsearch
  datahub_analytics_enabled: true
  datahub_standalone_consumers_enabled: false
  imageRegistry: "docker.io"

  elasticsearch:
    host: "elasticsearch-master"
    port: "9200"
    skipcheck: "false"
    insecure: "false"
    useSSL: "false"
    index:
      enableMappingsReindex: true
      enableSettingsReindex: true
      upgrade:
        cloneIndices: true
        allowDocCountMismatch: false
    search:
      maxTermBucketSize: 20
      exactMatch:
        exclusive: false
        withPrefix: true
        exactFactor: 2.0
        prefixFactor: 1.6
        caseSensitivityFactor: 0.7
        enableStructured: true
      graph:
        timeoutSeconds: 50
        batchSize: 1000
        maxResult: 10000

      custom:
        enabled: false
        config:
          queryConfigurations:
            - queryRegex: '[*]|'
              simpleQuery: false
              prefixMatchQuery: false
              exactMatchQuery: false
              boolQuery:
                must_not:
                  term:
                    deprecated:
                      value: true
              functionScore:
                functions:
                  - filter:
                      term:
                        materialized:
                          value: true
                    weight: 0.8
                score_mode: multiply
                boost_mode: multiply
            - queryRegex: >-
                ["'].+["']|\S+_\S+
              simpleQuery: false
              prefixMatchQuery: true
              exactMatchQuery: true
              functionScore:
                functions:
                  - filter:
                      term:
                        materialized:
                          value: true
                    weight: 0.8
                  - filter:
                      term:
                        deprecated:
                          value: true
                    weight: 0
                score_mode: multiply
                boost_mode: multiply
            # default
            - queryRegex: .*
              simpleQuery: true
              prefixMatchQuery: true
              exactMatchQuery: true
              boolQuery:
                must_not:
                  term:
                    deprecated:
                      value: true
              functionScore:
                functions:
                  - filter:
                      term:
                        materialized:
                          value: true
                    weight: 0.8
                score_mode: multiply
                boost_mode: multiply

  kafka:
    bootstrap:
      server: "kafka:9092"
    zookeeper:
      enabled: false
    topics:
      metadata_change_event_name: "MetadataChangeEvent_v4"
      failed_metadata_change_event_name: "FailedMetadataChangeEvent_v4"
      metadata_audit_event_name: "MetadataAuditEvent_v4"
      datahub_usage_event_name: "DataHubUsageEvent_v1"
      metadata_change_proposal_topic_name: "MetadataChangeProposal_v1"
      failed_metadata_change_proposal_topic_name: "FailedMetadataChangeProposal_v1"
      metadata_change_log_versioned_topic_name: "MetadataChangeLog_Versioned_v1"
      metadata_change_log_timeseries_topic_name: "MetadataChangeLog_Timeseries_v1"
      platform_event_topic_name: "PlatformEvent_v1"
      datahub_upgrade_history_topic_name: "DataHubUpgradeHistory_v1"
    metadataChangeLog:
      hooks:
        siblings:
          enabled: true
          consumerGroupSuffix: ''
        updateIndices:
          enabled: true
          consumerGroupSuffix: ''
        ingestionScheduler:
          enabled: true
          consumerGroupSuffix: ''
        incidents:
          enabled: true
          consumerGroupSuffix: ''
        entityChangeEvents:
          enabled: true
          consumerGroupSuffix: ''
        forms:
          enabled: true
          consumerGroupSuffix: ''
    maxMessageBytes: "5242880"  # 5MB
    producer:
      compressionType: none
      maxRequestSize: "5242880"  # 5MB
    consumer:
      maxPartitionFetchBytes: "5242880"  # 5MB
      stopContainerOnDeserializationError: true
    schemaregistry:
      type: INTERNAL
      # Confluent Kafka Implementation
      # type: KAFKA
      # url: "http://prerequisites-cp-schema-registry:8081"

  neo4j:
    host: "prerequisites-neo4j:7474"
    uri: "bolt://prerequisites-neo4j"
    usernameFromSecret: neo4j-secrets
    passwordFromSecret: neo4j-secrets

  sql:
    datasource:
      host: "prerequisites-mysql:3306"
      hostForMysqlClient: "prerequisites-mysql"
      port: "3306"
      url: "jdbc:mysql://prerequisites-mysql:3306/datahub?verifyServerCertificate=false&useSSL=true&useUnicode=yes&characterEncoding=UTF-8&enabledTLSProtocols=TLSv1.2"
      driver: "com.mysql.cj.jdbc.Driver"
      usernameFromSecret: mysql-secrets
      passwordFromSecret: mysql-secrets

  datahub:
    version: v0.14.0
    gms:
      protocol: "http"
      port: "8080"
      nodePort: "30001"
    frontend:
      validateSignUpEmail: true
    monitoring:
      enablePrometheus: true
      portName: jmx
    mae_consumer:
      port: "9091"
      nodePort: "30002"
    appVersion: "1.0"
    systemUpdate:
      enabled: true

    encryptionKey:
      secretRef: "datahub-encryption-secrets"
      secretKey: "encryption_key_secret"
      provisionSecret:
        enabled: true
        autoGenerate: true
        annotations: {}
    managed_ingestion:
      enabled: true
      defaultCliVersion: "0.14.0"
    metadata_service_authentication:
      enabled: false
      systemClientId: "__datahub_system"
      systemClientSecret:
        secretRef: "datahub-auth-secrets"
        secretKey: "system_client_secret"
      tokenService:
        signingKey:
          secretRef: "datahub-auth-secrets"
          secretKey: "token_service_signing_key"
        salt:
          secretRef: "datahub-auth-secrets"
          secretKey: "token_service_salt"
      # Set to false if you'd like to provide your own auth secrets
      provisionSecrets:
        enabled: true
        autoGenerate: true
        annotations: {}
    alwaysEmitChangeLog: false
    enableGraphDiffMode: true
    search_and_browse:
      show_search_v2: true  # If on, show the new search filters experience as of v0.10.5
      show_browse_v2: true  # If on, show the new browse experience as of v0.10.5
      backfill_browse_v2: true  # If on, run the backfill upgrade job that generates default browse paths for relevant entities

    ## v0.13.4+
    mcp:
      throttle:
        # updateIntervalMs: 60000
        ## Versioned MCL topic
        versioned:
          ## Whether to throttle MCP processing based on MCL backlog
          enabled: true
        #  threshold: 4000
        #  maxAttempts: 1000
        #  initialIntervalMs: 100
        #  multiplier: 10
        #  maxIntervalMs:  30000
        # Timeseries MCL topic
        timeseries:
          ## Whether to throttle MCP processing based on MCL backlog
          enabled: false
        #  threshold: 4000
        #  maxAttempts: 1000
        #  initialIntervalMs: 100
        #  multiplier: 10
        #  maxIntervalMs: 30000

#  hostAliases:
#    - ip: "192.168.0.104"
#      hostnames:
#        - "broker"
#        - "mysql"
#        - "postgresql"
#        - "elasticsearch"
#        - "neo4j"

## Add below to enable SSL for kafka
#  credentialsAndCertsSecrets:
#    name: datahub-certs
#    path: /mnt/datahub/certs
#    secureEnv:
#      ssl.key.password: datahub.linkedin.com.KeyPass
#      ssl.keystore.password: datahub.linkedin.com.KeyStorePass
#      ssl.truststore.password: datahub.linkedin.com.TrustStorePass
#      kafkastore.ssl.truststore.password: datahub.linkedin.com.TrustStorePass
#
#  springKafkaConfigurationOverrides:
#    ssl.keystore.location: /mnt/datahub/certs/datahub.linkedin.com.keystore.jks
#    ssl.truststore.location: /mnt/datahub/certs/datahub.linkedin.com.truststore.jks
#    kafkastore.ssl.truststore.location: /mnt/datahub/certs/datahub.linkedin.com.truststore.jks
#    security.protocol: SSL
#    kafkastore.security.protocol: SSL
#    ssl.keystore.type: JKS
#    ssl.truststore.type: JKS
#    ssl.protocol: TLS
#    ssl.endpoint.identification.algorithm:
#    basic.auth.credentials.source: USER_INFO
#    basic.auth.user.info: